"""
mgc_browser

An experimental SQLite based way to make gene catalog data more accessible.

Given a collection of metagenomic assemblies and an annotated gene catalog 
of all non-redundant called proteins from those assemblies, where all of the
preceding were generated by jmeppley/workflows:

Generate a SQLite databse linking annotations,genes,contigs, and samples
and provide methods to query this database.
"""

import re, sqlite3, pandas
from pypika import Query, Table, functions as sql_fn
from pypika.queries import QueryBuilder
from pypika.enums import JoinType
from pypika.terms import Field
from functools import reduce, partial

############################
# QUERY Functions


# user facing functions
class MGCBrowser():
    def __init__(self, sqlite_file):
        self.connection = sqlite3.connect(sqlite_file)
        self.query = partial(pandas.read_sql_query, con=self.connection)
        
    def get_annots_sql(self, **kwargs):
    """
    what: one of:
        column to return 
        list of columns to return
        "*"
        None (default): return columns used as keys
        
    EG:
        get_genes_sql(what="gene", EGGNOG=eggnog, order='Nitrososphaerales')
    """
        return self.query(get_annots_where(**kwargs))


def get_annots_sql(what=None, count=False, join=None, as_str=True, **kwargs):
    """
    what: one of:
        column to return 
        list of columns to return
        "*"
        None (default): return columns used as keys
    """
    where, query_columns = get_annots_where(join, **kwargs)
    if what is None:
        what = ['gene',] + query_columns
        
        
    return get_sql(TAX_TABLE, what, where,
                   joins = {FAM_TABLE: TAX_TABLE.gene == FAM_TABLE.gene},
                   count=count, count_string="gene",
                   as_str=as_str)



def get_genes_sql(what="*", count=False, as_str=True, join=None, include_annots=False, **kwargs):
    """
    Returns genes matching any combination of criteria. 
    """
    contig_args, gene_args = split_args(kwargs, CONTIG_DATA)
    gene_args, annot_args = split_args(gene_args, GENE_DATA)
    
    wheres = []
    columns = []
    joins = {}

    if len(annot_args) > 0:
        where, columns = get_annots_where(join, **annot_args)
        wheres.append(where)
        columns.append(columns)
        joins[FAM_TABLE] = GENE_TABLE.cluster_rep == FAM_TABLE.gene
        joins[TAX_TABLE] = GENE_TABLE.cluster_rep == TAX_TABLE.gene
    elif include_annots:
        if include_annots == "only":
            joins[FAM_TABLE] = GENE_TABLE.cluster_rep == FAM_TABLE.gene
            joins[TAX_TABLE] = GENE_TABLE.cluster_rep == TAX_TABLE.gene
        else:
            # us left join if we just want to annotate genes from other search
            joins[FAM_TABLE] = (GENE_TABLE.cluster_rep == FAM_TABLE.gene, JoinType.left)
            joins[TAX_TABLE] = (GENE_TABLE.cluster_rep == TAX_TABLE.gene, JoinType.left)

    if len(contig_args) > 0:
        where, columns = build_where(ContigFilter, **contig_args)
        wheres.append(where)
        columns.append(columns)
        joins[CONTIG_TABLE] = GENE_TABLE.contig == CONTIG_TABLE.contig

    if len(gene_args) > 0:
        where, columns = build_where(GeneFilter, **gene_args)
        wheres.append(where)
        columns.append(columns)
        
    return get_sql(GENE_TABLE, 
                   what, 
                   wheres,
                   join=join,
                   joins=joins,
                   count=count,
                   count_string="gene",
                   as_str=as_str)
    

def get_genes_by_contigs(contigs, what="*", count=False, as_str=True):
    """
    return table of genes with: contig and rep annotations for every gene on given contigs.
    
    contigs can be:
        string: a single contig name
        collection: a list of contig names
        pypika.queries.QueryBuilder: a pypika sql query
    """
    
    if isinstance(contigs, str):
        where = GENE_TABLE.contig == contigs
    else:
        where = GENE_TABLE.contig.isin(contigs)
        
    return get_sql(GENE_TABLE, what, where,
                   joins = {FAM_TABLE: (GENE_TABLE.cluster_rep == FAM_TABLE.gene, JoinType.left),
                            TAX_TABLE: (GENE_TABLE.cluster_rep == TAX_TABLE.gene, JoinType.left),
                           },
                   count=count, count_string="gene",
                   as_str=as_str)


def get_contigs_sql(what="*", count=False, as_str=True, join=None, **kwargs):
    contig_args, gene_args = split_args(kwargs, CONTIG_DATA)
    
    # if we only want counts or contig names, and there are no conditions in contig_data,
    #  skip the contig_data table and search gene_data
    if (count or what == 'contig') and len(contig_args) == 0:
        return get_genes_sql(what, as_str=as_str, count=count, join=join, **gene_args)

    # join contig_data query with contig query in genes
    wheres = []
    columns = []
    if len(contig_args) > 0:
        contig_args.setdefault('join', join if join is not None else "AND")
        where, columns = build_where(ContigFilter, **contig_args)
        wheres.append(where)
        columns.append(columns)

    if len(gene_args) > 0:
        gene_args['join'] = join
        genes_sql = get_genes_sql(what='contig', as_str=False, **gene_args)
        wheres.append(CONTIG_TABLE.contig.isin(genes_sql))
        columns.append(CONTIG_TABLE.contig)

    if what is None:
        what = columns

    return get_sql(CONTIG_TABLE, what, wheres, 
                   count=count, 
                   as_str=as_str, 
                   join=join, 
                   count_string='contig')


# Support functions and classes

def get_annots_where(join=None, **kwargs):
    fam_args, tax_args = split_args(kwargs, FAMS)
        
    if len(kwargs) == 0:
        raise Exception("Please suppl some criteria to filter genes")

    # default join for tax is "AND"
    tax_args.setdefault('join', join if join is not None else "AND")
    # default join for fams is "OR" (ignored for now)
    fam_args.setdefault('join', join if join is not None else "OR")
    
    # build filter clause (aka wheres)
    tax_where, tax_cols = build_where(TaxFilter, **tax_args)
    fam_where, fam_cols = build_where(FamFilter, **fam_args)

    if fam_where is not None:
        if tax_where is not None:
            where = fam_where & tax_where
        else:
            where = fam_where
    else:
        where = tax_where
    
    return where, tax_cols + fam_cols


def get_how(query):
    """
    special queries trigger special hows:
      * isnull
      * notnull
      * anything with a % triggers like
      * like or eq starting with ! trigers notlike or ne (not equal)
      * numeric values starting with ">", "<", "<=" or ">=" trigger le, gte, ...
    """
    if query is None:
        return "isnull", None
    if query in ['isnull', 'notnull']:
        return query, None
    if isinstance(query, (list, tuple, QueryBuilder)):
        return 'in', query
    if re.search(r'%', query):
        if query.startswith("!"):
            return "notlike", query
        else:
            return 'like', query
    m = re.search(r'^([<>]=?)(-?[.0-9]+)$', query)
    if m:
        comp, val_str = m.groups()
        try:
            value = int(val_str)
        except:
            try:
                value = float(val_str)
            except:
                value = None
        if value is not None:
            return comp, value
    return "eq", query

def get_where(query, column, how=None):
    """
    Use how to find set up where clause with column and data
    """
    (how, query) = get_how(query) if how is None else (how, query)
    if how in ['is', '==', '=', 'eq']:
        return (column == query) 
    elif how == 'isnull':
        return column.isnull()
    elif how == 'notnull':
        return column.notnull()
    elif how == 'notlike':
        return column.notlike(query)
    elif how == 'like':
        return column.like(query)
    elif how.upper() == 'REGEX':
        return column.regex(query)
    elif how == ">":
        return column.gt(query)
    elif how == "<":
        return column.lt(query)
    elif how == ">=":
        return column.gte(query)
    elif how == "<=":
        return column.lte(query)
    elif how == 'in':
        return column.isin(query)
    else:
        raise Exception("I don't know how to query with " + how)

class Filter():
    def __init__(self, query, how=None):
        self.where = get_where(query, self.column, how)        

TAX_TABLE = Table('taxon_annots')
RANKS = ['domain', 'phylum', 'class', 'order', 'family', 'genus', 'species']
RANK_COLS = {r:eval("TAX_TABLE.tax_{}".format(r)) for r in RANKS}

class TaxFilter(Filter):
    table = TAX_TABLE
    def __init__(self, rank, taxon, how=None):
        self.column = RANK_COLS[rank]
        super().__init__(taxon, how)

FAM_TABLE = Table('gene_families')
FAMS = ['COG', 'EGGNOG', 'KEGG', 'PFAM', 'TIGRFAM']
FAM_COLS = {r:eval("FAM_TABLE.{}".format(r)) for r in FAMS}
class FamFilter(Filter):
    table = FAM_TABLE
    def __init__(self, family, label, how=None):
        self.column = FAM_COLS[family]
        super().__init__(label, how)

CONTIG_TABLE = Table('contig_data')
CONTIG_DATA = ['length', 'coverage', 'gc','gene_count']
CONTIG_COLS = {c:eval("CONTIG_TABLE.{}".format(c)) for c in CONTIG_DATA}
class ContigFilter(Filter):
    table = CONTIG_TABLE
    def __init__(self, data, value, how=None):
        self.column = CONTIG_COLS[data]
        super().__init__(value, how)
        
GENE_TABLE = Table('gene_data')
GENE_DATA = ['contig', 'cluster_rep', 'gc','contig_start', 'contig_end', 'frame']
GENE_COLS = {c:eval("GENE_TABLE.{}".format(c)) for c in GENE_DATA}
class GeneFilter(Filter):
    table = GENE_TABLE
    def __init__(self, data, value, how=None):
        self.column = GENE_COLS[data]
        super().__init__(value, how)

        
def _get_join_fn(join):
    if join is None or join.lower() in ['and','&']:
        return lambda w1, w2: w1 & w2
    elif join.lower() in ['or','|']:
        return lambda w1, w2: w1 | w2
    elif join.lower() in ['xor','^']:
        return lambda w1, w2: w1 ^ w2
    else:
        raise Exception("Unknown way to join WHERE clauses: " + join)

def _clean_term(term):
    return re.sub(r'_$', '', term)
        
def build_where(filter_class, join='and', **kwargs):
    if len(kwargs) == 0:
        return None, []
    join_fn = _get_join_fn(join)
    filters = [filter_class(term, query) \
              for term, query in kwargs.items()]
    where = reduce(join_fn, [f.where for f in filters])
    columns = [f.column for f in filters]
    return where, columns
    
def get_sql(table, what="*", where=None, 
            count=False, 
            as_str=False, 
            joins={}, 
            count_string="*",
            join='AND'):
    """
    where can be a list or tuple of wheres. Will be joined by join.
    
    joins is a dict of table: where. EG:
        {FAM_TABLE: FAM_TABLE.gene == GENE_TABLE.cluster_id,}
    Joins are left joins unless where is a tuple of (where, jointype).
        
    if count is true, count on count_string (* by default)
    """
    # start query
    query = Query.from_(table)
    
    # add joined tables
    for join_table, join_where in joins.items():
        if isinstance(join_where, tuple):
            join_where, join_type = join_where
        else:
            join_type = JoinType.inner
        query = query.join(join_table, how=join_type).on(join_where)

    # what should be returned
    if count:
        # generate count, and package in list for later
        what = [sql_fn.Count(count_string),]
    else:
        # if they want everything, give them everything
        if what == "*":
            what = [t.star for t in [table,] + list(joins.keys())]
            
        # if they want one thing, put it in a list
        elif isinstance(what, (str, Field)):
            what = [what,] 
    query = query.select(*what)

    # filter if where is not None
    if where is not None:
        if isinstance(where, (tuple, list)):
            # put wheres together, usually with AND
            where = reduce(_get_join_fn(join), where)
        query = query.where(where)

    # return SQL string if requested
    if as_str:
        return str(query)
    return query
        

def build_sql(what, table, filter_class, count=False, as_str=False, **kwargs):
    where, columns = build_where(filter_class, **kwargs)
    if what is None:
        what = columns
    return get_sql(table, what, where, count, as_str)

def split_args(kwargs, keep_keys):
    matched_args = {}
    other_args = {}
    keep = set(keep_keys)
    for key, value in kwargs.items():
        key = _clean_term(key)
        if key in keep:
            matched_args[key] = value
        else:
            other_args[key] = value
    return matched_args, other_args


##########################
# DB creation (untested, just copied from notebook:
# notebooks/delong/AlohaGenes2.0/mgc_browser/Prototype_001_upload_data.ipynb)
from jme.jupy_tools.cdhit import parse_multiple_clusters

def create_mgc_db(sqlite_file,
                  assembly_dirs_glob,
                  catalog_annotations,
                  gene_faas,
                  cluster_files,
                  glob_style='glob',
                 ):
    """
    Turn assemblies and catalog into SQLite DB
    
    Params:
     * sqlite_file: location to create DB
     * assembly_dirs_glob: glob to find asembly dirs
     * catalog_annotations: tab separated annotation table
     * gene_faas: list of faa files with gene sequences
     * cluster_files: list of cdhit .clstr files, newest first if multiple 
     * glob_style: glob or glob_wildcards
     
    Currenlty this just creates the SQLite bulk import files
    TODO: hook up SQLite command
    """
    
    if glob_style.lower() == 'glob':
        from glob import glob
        assembly_dirs = glob(assembly_dirs_glob)
    else:
        from jme.jupy_tools.filesystem import glob_wildcards
        assembly_dirs = [f[0] for f in glob_wildcards(assembly_dirs_glob)]
        
    # process annotations
    gene_cols, annot_bulk_file, fams_bulk_file = process_annots(catalog_annotations)

    # process clusters
    clusters = parse_multiple_clusters(cluster_files)
    cluster_reps = {g:clusters[1][c] for g,c in clusters[2].items()}
    contig_counts, gene_bulk_file = process_gene_data(gene_faas, cluster_reps)
    contig_counts = pandas.DataFrame({'gene_count': contig_counts})

    # process contigs
    contig_bulk_file = process_contig_data(assembly_dirs, contig_counts)

    # load SQL
    with open("bulk.tax.cmds", 'w') as BC:
        BC.write("""
DROP TABLE if exists taxon_annots;
CREATE TABLE taxon_annots (gene text, tax_species text, tax_genus text, tax_family text, tax_order text, tax_class text, tax_phylum text, tax_domain text, function text, min_pct_ID real, hit_count int, top_hit text, top_pct_ID real, top_score real, top_desc real);
CREATE INDEX taxon_annots_gene ON taxon_annots(gene);
""")
        for rank in ['domain','phylum','class','order','family','genus','species']:
            BC.write("CREATE INDEX taxon_annots_{rank} ON taxon_annots({rank});".format(rank="tax_" + rank))

        BC.write("""
.separator |
.import annot.bulk taxon_annots
""")

    # TODO
    #!sqlite3 {sqlite_db} -batch -bail < bulk.tax.cmds

    # TIGRFAM	PFAM	KEGG	EGGNOG	COG
    with open("bulk.gf.cmds", 'w') as BC:
        BC.write("""
DROP TABLE if exists gene_families;
CREATE TABLE gene_families (gene txt, TIGRFAM txt, PFAM txt, KEGG txt, EGGNOG txt, COG txt);
CREATE INDEX gene_families_gene ON gene_families(gene);
CREATE INDEX gene_families_COG ON gene_families(COG);
CREATE INDEX gene_families_EGGNOG ON gene_families(EGGNOG);
CREATE INDEX gene_families_KEGG ON gene_families(KEGG);
CREATE INDEX gene_families_PFAM ON gene_families(PFAM);
CREATE INDEX gene_families_TIGRFAM ON gene_families(TIGRFAM);

.separator |
.import gene_fams.bulk gene_families
""")

    # TODO
    #!sqlite3 {sqlite_db} -batch -bail < bulk.gf.cmds

    with open("bulk.gene.cmds", 'w') as BC:
        BC.write("""
DROP TABLE if exists gene_data;
CREATE TABLE gene_data (gene txt, gc real, cluster_rep txt, contig text, contig_start int, contig_end int, contig_frame int);
CREATE UNIQUE INDEX gene_data_gene ON gene_data(gene);
CREATE INDEX gene_data_rep ON gene_data(cluster_rep);
CREATE INDEX gene_data_contig ON gene_data(contig);

.separator |
.import gene_data.bulk gene_data
""")

    # TODO
    #!sqlite3 {sqlite_db} -batch -bail < bulk.gene.cmds

    with open("bulk.contig.cmds", 'w') as BC:
        BC.write("""
DROP TABLE if exists contig_data;
CREATE TABLE contig_data (contig txt, length int, coverage real, gc real, gene_count int);
CREATE INDEX contig_data_contig ON contig_data(contig);

.separator |
.import contig_data.bulk contig_data
    """)

    # TODO
    #!sqlite3 {sqlite_db} -batch -bail < bulk.contig.cmds
    

# loading helper functions

def load_annots(annot_file):
    """ reads the text file into a DataFrame """
    return pandas.read_csv(annot_file, sep='\t', index_col=0)

def write_bulk_table(data, file_name, sep="|"):
    """ Format table for bulk import to SQLite"""
    data.to_csv(file_name, sep=sep, header=None)

def get_gene_fam_columns(columns):
    """ return the ALLCAPS column names on the right """
    gene_fam_cols = []
    for c in reversed(columns):
        if c.upper() == c:
            gene_fam_cols.append(c)
    return gene_fam_cols

def process_annots(annot_file, annot_bulk="annot.bulk", gene_fams_bulk="gene_fams.bulk"):
    """ Loads annotation file and dumps in two parts to bulk files for SQL import """
    annots = load_annots(annot_file)
    print("loaded annotations: " + str(annots.shape))

    # dump tax columns for bulk upload
    tax_cols = annots.columns[:14]
    print("writing to " + annot_bulk)
    write_bulk_table(annots[tax_cols], annot_bulk)
    
    # dump gene columns for bulk upload
    gene_cols = get_gene_fam_columns(annots.columns)
    print("writing " + repr(gene_cols) + " to " + gene_fams_bulk)
    write_bulk_table(annots[gene_cols], gene_fams_bulk)
    return gene_cols, annot_bulk, gene_fams_bulk

def process_gene_data(gene_faas, cluster_reps, gene_bulk='gene_data.bulk'):
    """
    parses faa headers (from prodigal) to generate table of gene data with:
        gene, contig, start, end, cluster_rep (puled from cluster_reps dict)

    returns contig gene counts as dict
    """
    contig_counts = {}
    gene_rexp = re.compile(r'^>((\S+)_(\d+))\s+#\s+(\d+)\s+#\s+(\d+)\s+#\s+(-?\d+)\s.+;gc_cont=([0-9.]+).*')
    def repl(match):
        """
        DB cols: gene, gc, cluster_rep, contig, contig_start, contig_end, contig_frame
        """
        gene, contig, gene_no, start, end, frame, gc = match.groups()
        contig_counts[contig] = contig_counts.get(contig, 0) + 1
        return "|".join((gene, gc, cluster_reps[gene], contig, start, end, frame))

    with open(gene_bulk, 'wt') as BULK:
        for f in gene_faas:
            with open(f) as F:
                for line in F:
                    if line.startswith(">"):
                        BULK.write(gene_rexp.sub(repl, line))
    
    return contig_counts, gene_bulk

# find contig data in assembliy folders

# generic tool for finding files
def filter_item(name, filters):
    """ does this name match ANY of the filters? """
    for f in filters:
        if f(name):
            return True
    return False

def find_files(path, **kwargs):
    """ walk a path looking for files that match filters 
        dir_filters: functions that return True for folders to skip
        file_filters: functions that return True for files to keep
    """
    dir_filters = kwargs.get('dir_filters', [])
    file_filters = kwargs.get('file_filters', [])
    for dirpath, dirnames, filenames in os.walk(path):
        # drop dir
        for dirname in [d for d in dirnames if filter_item(d, dir_filters)]:
            dirnames.remove(dirname)
        for filename in filenames:
            if filter_item(filename, file_filters):
                yield os.path.join(dirpath, filename)

def process_contig_data(assembly_dirs, contig_counts,
                        contig_bulk='contig_data.bulk',
                        stats_file_name='contigs.all.stats.txt'):
    """
    Walk the given assembly dirs looking for stats files of the given name
    
    Add gene counts to tables from contig_counts parameter.
    """
    if isinstance(contig_counts, dict):
        contig_counts = pandas.DataFrame({'gene_count': contig_counts})
    
    def contig_stats_filter(filename):
        return filename == stats_file_name

    with open(contig_bulk, 'wt', newline='') as BULK:
        for assemblies_root in assembly_dirs:
            print("looking for " + 
                  stats_file_name +
                  " in " + assemblies_root
                 )
            count = 0
            for stats_file in find_files(assemblies_root, file_filters=[contig_stats_filter]):
                # ['Contig', 'GC', 'Length', 'MeanCov']
                stats_table = pandas.read_csv(stats_file, 
                                              sep='\t', 
                                              usecols=[0,1,2,11], 
                                              index_col=0)
                
                # contig_data (contig txt, length int, coverage real, gc real)
                stats_table[['Length','MeanCov','GC']].join(contig_counts).to_csv(BULK, sep='|', header=None)
                count += 1
            print("Found %d files" % count)
            
    return contig_bulk